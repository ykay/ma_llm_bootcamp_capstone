{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rtargaryen/Code/codepath/llm_bootcamp/capstone/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/rtargaryen/Code/codepath/llm_bootcamp/capstone/.venv/lib/python3.12/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in EntityExtractor has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# SET UP METADATA EXTRACTORS (ENTITYEXTRACTOR IS COMMENTED OUT BECAUSE IT SEEMS TO HAVE SOME ISSUES ref: https://github.com/run-llama/llama_index/issues/13774)\n",
    "\n",
    "from llama_index.core.extractors import TitleExtractor, QuestionsAnsweredExtractor, SummaryExtractor\n",
    "from llama_index.extractors.entity import EntityExtractor\n",
    "\n",
    "title_extractor = TitleExtractor()\n",
    "\n",
    "# entity_extractor = EntityExtractor(label_entities=True, device=\"cpu\")\n",
    "\n",
    "questions_answered_extractor = QuestionsAnsweredExtractor()\n",
    "\n",
    "summary_extractor = SummaryExtractor()\n",
    "\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "node_parser = SentenceSplitter(chunk_size=1000, chunk_overlap=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD TRANSCRIPT DATA\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "import re\n",
    "\n",
    "# This function receives the filename and allows you to return a dictionary with any custom metadata.\n",
    "def filename_fn(filename):\n",
    "    # Extract number using regular expression\n",
    "    number = re.findall(r'\\d+', filename)\n",
    "\n",
    "    # Convert the list of matched numbers to an integer (or use it directly as string)\n",
    "    week_number = 0\n",
    "    if number:\n",
    "        week_number = int(number[0])\n",
    "\n",
    "    return {\n",
    "        \"source\": f\"This was mentioned by Tim Lee during Week {week_number} of the LLM Bootcamp\",\n",
    "    }\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "  input_files=[\"./data/llm_bootcamp_week1_transcript.txt\"],\n",
    "  # file_metadata=filename_fn,\n",
    ").load_data()\n",
    "\n",
    "documents += SimpleDirectoryReader(\n",
    "  input_files=[\"./data/llm_bootcamp_week2_transcript.txt\"],\n",
    "  # file_metadata=filename_fn,\n",
    ").load_data()\n",
    "\n",
    "documents += SimpleDirectoryReader(\n",
    "  input_files=[\"./data/llm_bootcamp_week3_transcript.txt\"],\n",
    "  # file_metadata=filename_fn,\n",
    ").load_data()\n",
    "\n",
    "documents += SimpleDirectoryReader(\n",
    "  input_files=[\"./data/llm_bootcamp_week4_transcript.txt\"],\n",
    "  # file_metadata=filename_fn,\n",
    ").load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:35<00:00,  2.81it/s]\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "\n",
    "pipeline = IngestionPipeline(transformations=[node_parser, summary_extractor])\n",
    "\n",
    "nodes = pipeline.run(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "{'file_path': 'data/llm_bootcamp_week1_transcript.txt', 'file_name': 'llm_bootcamp_week1_transcript.txt', 'file_type': 'text/plain', 'file_size': 101098, 'creation_date': '2024-10-06', 'last_modified_date': '2024-10-06', 'section_summary': 'The key topics discussed in the section include the statelessness of llms, the parallelizability of llm serving, performance testing of llms, streaming from llms, the process of llm prediction (inference), and the use of open AI for web server standardization. The entities mentioned include llms, web servers, tokens per second rate, AI solutions, inference, and open AI rest API.'}\n",
      "{'file_path': 'data/llm_bootcamp_week1_transcript.txt', 'file_name': 'llm_bootcamp_week1_transcript.txt', 'file_type': 'text/plain', 'file_size': 101098, 'creation_date': '2024-10-06', 'last_modified_date': '2024-10-06', 'section_summary': \"The section discusses the use of OpenAI for web servers, the standardization around OpenAI's REST API and streaming API, the organization of messages using the concept of role and content, the importance of tuning the temperature parameter when using chat GPT, the various options for GPU rentals, the cost implications of running custom fine-tuned models on dedicated GPUs, and the recommendation of using Runpod as a cost-effective serverless option. The section also mentions the availability of cheap hosting options and the increasing competition leading to lower API prices. The section encourages participants to share their insights and experiences, including playing with AMA and exploring different providers for GPU rentals.\"}\n",
      "{'file_path': 'data/llm_bootcamp_week1_transcript.txt', 'file_name': 'llm_bootcamp_week1_transcript.txt', 'file_type': 'text/plain', 'file_size': 101098, 'creation_date': '2024-10-06', 'last_modified_date': '2024-10-06', 'section_summary': 'The section discusses the goals of the class, which include familiarizing students with AI and ML vocabulary, providing intuition for building AI solutions, understanding model sizes and parameters, exploring the impact of quantization on model behavior, and learning about agents and agentic programming. The section emphasizes the importance of practical experience and intuition in the field of AI and ML. Key entities mentioned include model sizes, parameters, quantization, agents, and agentic programming.'}\n",
      "{'file_path': 'data/llm_bootcamp_week2_transcript.txt', 'file_name': 'llm_bootcamp_week2_transcript.txt', 'file_type': 'text/plain', 'file_size': 104379, 'creation_date': '2024-10-06', 'last_modified_date': '2024-10-06', 'section_summary': 'The key topics of the section include Tim Lee discussing the importance of understanding and guiding technology solutions, setting up a personal smart assistant for email using Openai, hosting embeddings locally for privacy concerns, milestones in fetching and indexing emails, the use of frameworks like Lama Index and lang chain, the benefits of DIY coding for better control and intuition, and the importance of iterative processes in human decision-making. Tim Lee also mentions having jury duty. Key entities mentioned include Tim Lee, Gmail, Openai, Netflix, Lama Index, lang chain, and jury duty.'}\n",
      "{'file_path': 'data/llm_bootcamp_week4_transcript.txt', 'file_name': 'llm_bootcamp_week4_transcript.txt', 'file_type': 'text/plain', 'file_size': 64698, 'creation_date': '2024-10-06', 'last_modified_date': '2024-10-06', 'section_summary': 'The key topics discussed in this section include the concept of self-consistency in model calls, the importance of specifying additional parameters for function execution, the use of GPT-4.0 models, and the significance of using the \"use tools\" flag in code. The entities involved in the conversation are Tim Lee, denisura, and itasari. Tim Lee provides insights on model calls and techniques, denisura shares experiences with model usage and troubleshooting, and itasari expresses gratitude and bids good night.'}\n",
      "LLM will see the following when querying:\n",
      " [Excerpt from document]\n",
      "file_path: data/llm_bootcamp_week1_transcript.txt\n",
      "section_summary: The section discusses the excitement and challenges of working with agents, the CodePath program, the importance of attendance and participation in the course, and the consequences of not meeting course requirements. It emphasizes the need for dedication, curiosity, and high expectations in acquiring knowledge and skills during the program.\n",
      "Excerpt:\n",
      "-----\n",
      "gonna learn all about agents right um but you're going to find out pretty\n",
      "11:19\n",
      "quickly working with agents man when they work so cool it's so sci-fi the age\n",
      "11:26\n",
      "that we're in is ridiculous I cannot believe it right I mean this is this to me has been such an exciting time but at\n",
      "11:32\n",
      "the same time you're going to quickly see how how hard agents fall on their face and so you're going to you're going\n",
      "11:39\n",
      "to begin to explore okay well I'm starting to understand where they are now and these are kind of how I'm going\n",
      "11:45\n",
      "to amarate you know their their shortcomings right so um and then the\n",
      "11:53\n",
      "the final thing is you know I've always love codepath um students by the way the\n",
      "11:59\n",
      "brand for this uh you know codepath is kind of our University brand this is Max Academy as we go to the max max Academy\n",
      "12:06\n",
      "is what you're part of now uh but it's the same Vibe so basically I love the\n",
      "12:12\n",
      "original folks in codepath because you know you're so curious and you're passionate about this like\n",
      "12:17\n",
      "self-development and you want to do things hardcore right and so it was always cool\n",
      "12:23\n",
      "to come together with this group and and have super high expectations and and um\n",
      "12:31\n",
      "you know just be very very curious you know so many of you have jobs that I know are high press like no one in\n",
      "12:36\n",
      "Silicon Valley I've ever met has been like oh yeah I'm just chilling everyone's like man I'm slammed at work\n",
      "12:43\n",
      "a lot of people have kids you know so I think that this space was kind of a\n",
      "12:48\n",
      "place where like okay let's pull off our Band-Aid let's focus for six hours uh\n",
      "12:53\n",
      "for six weekends and then we will acquire this knowledge that has been in the air now for a year let's get it now\n",
      "13:01\n",
      "let's put it in our brains and then let's choose what we want to do with it right because you also know um that so\n",
      "13:08\n",
      "um our policies uh will stay the same when it comes to course policies so our course policies is that this is this is\n",
      "13:15\n",
      "for the non- Rippling folks right so we have a couple Rippling folks auditing and and you're and this is not going to apply to you but for the rest of you\n",
      "13:22\n",
      "it's um mandatory attendance for the six sessions just six sessions right it's going to be six quick two-hour sessions\n",
      "13:29\n",
      "you're going to be loaded with knowledge um and abilities so six six sessions you can use excused absences though right so\n",
      "13:36\n",
      "if you if you email me and say hey I can't attend no I'll say no problem at all watch a recorded video I'll note it\n",
      "13:42\n",
      "down but if you ghost then you're out you know so if you g to session you're out if you don't turn in one of the\n",
      "13:49\n",
      "weekly assignments um by uh by Sunday at midnight then you're also out um and\n",
      "13:56\n",
      "I'll just remind you why we did this because we've tested this I've tested this like approximately one trillion times all different ways because it's\n",
      "14:02\n",
      "actually exhausting to maintain the standard um and Chase everyone down and kind of like have the talk and all this\n",
      "14:08\n",
      "other stuff but what would happen is when we didn't have that you're really well intentioned I hope you're excited\n",
      "14:14\n",
      "today I'm very excited what happens is work deadline did whatever whatever life\n",
      "14:21\n",
      "something uh and you I can't I can't I just can't can't do it this week uh and\n",
      "14:27\n",
      "you don't turn in the project you don't show up and then I'll I'll let you guess how many people come back once they drop\n",
      "14:33\n",
      "off it's a very small number so once you're gone I typically never see you\n",
      "14:39\n",
      "again and so um basically we have these rules because it creates a little bit of\n",
      "14:44\n",
      "a forcing function to stay with it and also be surrounded by a group of people that are as intense and are as serious\n",
      "14:51\n",
      "to get this kind of knowledge and and have some fun with this in this time period so um sorry for springing this on\n",
      "14:59\n",
      "you for the non code paths I know that because it's it's like I think 90% excode path here and just a few\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# SOME DEBUG PRINTING TO SEE WHAT THE NODES LOOK LIKE\n",
    "\n",
    "from llama_index.core.schema import MetadataMode\n",
    "\n",
    "print(len(nodes))\n",
    "print(nodes[0].metadata)\n",
    "print(nodes[1].metadata)\n",
    "print(nodes[2].metadata)\n",
    "\n",
    "\n",
    "print(nodes[int(len(nodes)/2)].metadata)\n",
    "print(nodes[len(nodes)-1].metadata)\n",
    "\n",
    "# print(type(nodes[3])) # This prints the type of the node: <class 'llama_index.core.schema.TextNode'>\n",
    "# print(nodes[3].text) # This prints the original snippet of text\n",
    "print( # Another way \n",
    "    \"LLM will see the following when querying:\\n\",\n",
    "    (nodes)[3].get_content(metadata_mode=MetadataMode.LLM),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMPLE QUERIES TO TEST\n",
    "queries = [\n",
    "  \"What did Tim talk about during week 2?\",\n",
    "  \"What was the thing about Sunday midnight?\",\n",
    "  \"When was the thing about Sunday midnight discussed?\",\n",
    "  \"Tim Lee mentioned something about HR policy in the LLM Bootcamp. Can you find the week he mentioned it and explain what he was talking about?\",\n",
    "  \"What were some topics from Week 4?\",\n",
    "  \"How many lecture weeks have happened so far?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 3 sub questions.\n",
      "\u001b[1;3;38;2;237;90;200m[llm_bootcamp_transcripts] Q: By first identifying and quoting from the most relevant lecture week and pointing to a timestamp when something was mentioned, what topics did Tim cover during week 2?\n",
      "\u001b[0m\u001b[1;3;38;2;90;149;237m[llm_bootcamp_transcripts] Q: By first identifying and quoting from the most relevant lecture week and pointing to a timestamp when something was mentioned, what key points did Tim emphasize in week 2?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203m[llm_bootcamp_transcripts] Q: By first identifying and quoting from the most relevant lecture week and pointing to a timestamp when something was mentioned, were there any specific examples or case studies discussed by Tim in week 2?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203m[llm_bootcamp_transcripts] A: In week 2, Tim Lee discussed the concept of summarization and provided a specific example related to document compression. He mentioned, \"imagine a world where you take that document. You generate that cliff notes, and then you put it in the context, and you do the embeddings,\" at timestamp 1:00:15. This illustrates the idea of creating compressed summaries of documents using techniques like generating cliff notes and embeddings.\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200m[llm_bootcamp_transcripts] A: During week 2, Tim Lee covered several important topics related to the homework assignments and the capstone project. He emphasized the importance of understanding the code and working on the capstone project, stating, \"your mission is more just to like to understand the code\" (1:40:21). He also discussed the process of designing evaluations in LLM coding, mentioning that \"so much of Llm. Coding is just designing a prompt\" (1:17:04). Additionally, he highlighted the significance of data inspection and curation, noting that \"people underestimate how much both data inspection as well as like data, curation and data improvement\" is necessary to improve a system (56:22).\n",
      "\u001b[0m\u001b[1;3;38;2;90;149;237m[llm_bootcamp_transcripts] A: In week 2, Tim emphasized several key points regarding data inspection, curation, and improvement in systems. He stated, \"people underestimate how much both data inspection as well as like data, curation and data improvement that your role is versus to improve a system like this\" at timestamp 56:22. He also discussed the importance of query optimization, mentioning that \"there's a a phase that people do which is query optimization\" at timestamp 1:36:29. Additionally, he highlighted the significance of evaluating questions for quality, stating, \"you have to put on a separate like scrutiny\" at timestamp 1:19:48. These points collectively underscore the critical role of human involvement and iterative processes in enhancing system performance.\n",
      "\u001b[0mAnswer to 'What did Tim talk about during week 2?':\n",
      "During week 2, Tim Lee covered several important topics, including the significance of understanding code and working on the capstone project. He emphasized that \"your mission is more just to like to understand the code\" at timestamp 1:40:21. He also discussed designing evaluations in LLM coding, stating that \"so much of Llm. Coding is just designing a prompt\" at 1:17:04. Additionally, he highlighted the importance of data inspection and curation, noting that \"people underestimate how much both data inspection as well as like data, curation and data improvement\" is necessary to enhance a system at 56:22. Furthermore, he touched on query optimization and evaluating questions for quality, underscoring the critical role of human involvement in improving system performance.\n",
      "Generated 1 sub questions.\n",
      "\u001b[1;3;38;2;237;90;200m[llm_bootcamp_transcripts] Q: By first identifying and quoting from the most relevant lecture week and pointing to a timestamp when something was mentioned, what was discussed about Sunday midnight?\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200m[llm_bootcamp_transcripts] A: The discussion about Sunday midnight pertains to the weekly project deadline. It was mentioned at the timestamp 1:55:24, where it states, \"that's the weekly project it's due Sunday at midnight.\"\n",
      "\u001b[0mAnswer to 'What was the thing about Sunday midnight?':\n",
      "The discussion about Sunday midnight relates to the weekly project deadline, which is due at that time.\n",
      "Generated 1 sub questions.\n",
      "\u001b[1;3;38;2;237;90;200m[llm_bootcamp_transcripts] Q: By first identifying and quoting from the most relevant lecture week and pointing to a timestamp when something was mentioned, when was the thing about Sunday midnight discussed?\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200m[llm_bootcamp_transcripts] A: The discussion about the project being due on Sunday at midnight was mentioned in the first week of the lecture at timestamp 1:55:24. The exact quote is: \"okay so that's the weekly project it's due Sunday at midnight.\"\n",
      "\u001b[0mAnswer to 'When was the thing about Sunday midnight discussed?':\n",
      "The discussion about the project being due on Sunday at midnight was mentioned in the first week of the lecture at timestamp 1:55:24.\n",
      "Generated 2 sub questions.\n",
      "\u001b[1;3;38;2;237;90;200m[llm_bootcamp_transcripts] Q: By first identifying and quoting from the most relevant lecture week and pointing to a timestamp when something was mentioned, what did Tim Lee say about HR policy?\n",
      "\u001b[0m\u001b[1;3;38;2;90;149;237m[llm_bootcamp_transcripts] Q: By first identifying and quoting from the most relevant lecture week and pointing to a timestamp when something was mentioned, in which week did Tim Lee discuss HR policy?\n",
      "\u001b[0m\u001b[1;3;38;2;90;149;237m[llm_bootcamp_transcripts] A: Tim Lee discussed HR policy during week 2 of the bootcamp. This is mentioned at the timestamp 1:36:16, where he asks, \"What is the Tim Lee: Hr policy for vacations in Canada for my company?\"\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200m[llm_bootcamp_transcripts] A: In the second week of the bootcamp, Tim Lee discussed HR policy in relation to vacation policies. He mentioned, \"What is the Hr policy for vacations in Canada for my company?\" at timestamp 1:36:16. He then elaborated on the need to possibly modify the query to be less specific, saying, \"Maybe I would modify that query to... what are vacation policies in general?\" at 1:36:29. This indicates his approach to understanding HR policies by considering broader aspects rather than just regional specifics.\n",
      "\u001b[0mAnswer to 'Tim Lee mentioned something about HR policy in the LLM Bootcamp. Can you find the week he mentioned it and explain what he was talking about?':\n",
      "Tim Lee mentioned HR policy during week 2 of the bootcamp. He specifically discussed vacation policies, asking, \"What is the Hr policy for vacations in Canada for my company?\" at timestamp 1:36:16. He further elaborated on the topic by suggesting that it might be beneficial to broaden the inquiry, stating, \"Maybe I would modify that query to... what are vacation policies in general?\" at 1:36:29. This reflects his approach to understanding HR policies by looking at more general principles rather than focusing solely on specific regional regulations.\n",
      "Generated 3 sub questions.\n",
      "\u001b[1;3;38;2;237;90;200m[llm_bootcamp_transcripts] Q: By first identifying and quoting from the most relevant lecture week and pointing to a timestamp when something was mentioned, what were the main topics discussed in Week 4?\n",
      "\u001b[0m\u001b[1;3;38;2;90;149;237m[llm_bootcamp_transcripts] Q: By first identifying and quoting from the most relevant lecture week and pointing to a timestamp when something was mentioned, were there any guest speakers in Week 4?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203m[llm_bootcamp_transcripts] Q: By first identifying and quoting from the most relevant lecture week and pointing to a timestamp when something was mentioned, what assignments were given in Week 4?\n",
      "\u001b[0m\u001b[1;3;38;2;90;149;237m[llm_bootcamp_transcripts] A: There were no guest speakers mentioned in Week 4. The focus was primarily on Tim Lee discussing the progress of the LLM bootcamp and the upcoming topics, including agents and the capstone demo. For instance, at 3:10, Tim Lee introduces the concept of agents and mentions Devon AI as a reference point for learning about agents.\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203m[llm_bootcamp_transcripts] A: In Week 4, Tim Lee discussed the upcoming capstone demo and emphasized the importance of understanding vocabulary and concepts in the field of LLMs. He stated, \"you should have everything that you need knowledge wise to implement your capstone. You know. That we're gonna demo in a couple of weeks\" at timestamp 1:01. This indicates that the main assignment for Week 4 was to prepare for the capstone project demo.\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200m[llm_bootcamp_transcripts] A: In Week 4, the main topics discussed included the importance of understanding vocabulary and concepts in the field of LLMs, the completion of function calling, and the upcoming capstone demo. Tim Lee emphasized the significance of these topics by stating, \"you should have everything that you need knowledge-wise to implement your capstone\" at timestamp 1:01. Additionally, he introduced the concepts of agentic programming and fine-tuning, noting, \"we're like, what the heck does everyone mean by when they're talking about that?\" at timestamp 1:35.\n",
      "\u001b[0mAnswer to 'What were some topics from Week 4?':\n",
      "Some topics discussed in Week 4 included the importance of understanding vocabulary and concepts in the field of LLMs, the completion of function calling, and the upcoming capstone demo. Tim Lee highlighted these topics by stating, \"you should have everything that you need knowledge-wise to implement your capstone\" at timestamp 1:01. Additionally, he introduced the concepts of agentic programming and fine-tuning, noting, \"we're like, what the heck does everyone mean by when they're talking about that?\" at timestamp 1:35.\n",
      "Generated 1 sub questions.\n",
      "\u001b[1;3;38;2;237;90;200m[llm_bootcamp_transcripts] Q: By first identifying and quoting from the most relevant lecture week and pointing to a timestamp when something was mentioned, how many lecture weeks have been covered in the course?\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200m[llm_bootcamp_transcripts] A: The course has covered four lecture weeks. This is indicated in the fourth week's lecture where Tim Lee states, \"Okay, all right, welcome everybody to session 4. We've only been doing this for 4 weeks,\" at the timestamp 0:02.\n",
      "\u001b[0mAnswer to 'How many lecture weeks have happened so far?':\n",
      "Four lecture weeks have happened so far.\n"
     ]
    }
   ],
   "source": [
    "# METADATA EXTRACTION FOR BETTER DOCUMENT INDEXING + \n",
    "# SUBQUESTION QUERY ENGINE FOR ALL QnA PIPELINES\n",
    "# ref: https://docs.llamaindex.ai/en/stable/examples/metadata_extraction/MetadataExtractionSEC/\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.1, model=\"gpt-4o-mini\", max_tokens=512)\n",
    "\n",
    "from llama_index.core.question_gen import LLMQuestionGenerator\n",
    "from llama_index.core.question_gen.prompts import (\n",
    "    DEFAULT_SUB_QUESTION_PROMPT_TMPL,\n",
    ")\n",
    "\n",
    "question_gen = LLMQuestionGenerator.from_defaults(\n",
    "    llm=llm,\n",
    "    prompt_template_str=\"\"\"\n",
    "        Follow the example, but instead of giving a question, always prefix the question \n",
    "        with: 'By first identifying and quoting from the most relevant lecture week and pointing to a timestamp when something was mentioned, '. \n",
    "        \"\"\"\n",
    "    + DEFAULT_SUB_QUESTION_PROMPT_TMPL,\n",
    ")\n",
    "\n",
    "\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.query_engine import SubQuestionQueryEngine\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings\n",
    "\n",
    "index = VectorStoreIndex(nodes=nodes, llm=llm)\n",
    "engine = index.as_query_engine(similarity_top_k=10)\n",
    "\n",
    "final_engine = SubQuestionQueryEngine.from_defaults(\n",
    "    query_engine_tools=[\n",
    "        QueryEngineTool(\n",
    "            query_engine=engine,\n",
    "            metadata=ToolMetadata(\n",
    "                name=\"llm_bootcamp_transcripts\",\n",
    "                description=\"Transcripts from lecture video recordings.\",\n",
    "            ),\n",
    "        )\n",
    "    ],\n",
    "    question_gen=question_gen,\n",
    "    use_async=True,\n",
    ")\n",
    "\n",
    "for query in queries:\n",
    "    response = final_engine.query(query)\n",
    "    print(f\"Answer to '{query}':\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer to 'What did Tim talk about during week 2?':\n",
      "During week 2, Tim Lee led a breakout room session where participants were tasked with answering questions and explaining concepts to each other. He emphasized the importance of understanding by encouraging participants to articulate their thoughts and come up with additional questions. Tim also demonstrated a project involving a data folder and a file with tracing callback handlers, which was related to a five-year strategic plan document that was 55 pages long. Participants were encouraged to follow along with the demonstration and engage in discussions for better comprehension.\n",
      "Answer to 'What was the thing about Sunday midnight?':\n",
      "The mention of Sunday at midnight refers to the deadline for turning in one of the weekly assignments. If the assignment is not submitted by that time, it could result in being dropped from the course.\n",
      "Answer to 'When was the thing about Sunday midnight discussed?':\n",
      "The provided excerpts do not mention anything about Sunday midnight.\n",
      "Answer to 'Tim Lee mentioned something about HR policy in the LLM Bootcamp. Can you find the week he mentioned it and explain what he was talking about?':\n",
      "Tim Lee mentioned HR policy during the second week of the LLM Bootcamp. He discussed vacation policies, specifically in the context of querying for information about HR policies in Canada. He emphasized the importance of query optimization, suggesting that users might need to modify their queries to be less specific or to explore general vacation policies, as the handbook might not contain region-specific information. He also highlighted techniques for improving the effectiveness of queries, such as expanding them and using different terms to ensure comprehensive information retrieval.\n",
      "Answer to 'What were some topics from Week 4?':\n",
      "Some topics discussed in Week 4 included the completion of function calling, the upcoming capstone demo, agentic programming, and fine-tuning to improve LLM behavior. Additionally, the concept of agents was introduced, with a reference to Devon AI for learning about agents.\n",
      "Answer to 'How many lecture weeks have happened so far?':\n",
      "One and a half weeks of the class have occurred so far.\n"
     ]
    }
   ],
   "source": [
    "# This just shows a basic use of the query engine without any subquestions or metadata extraction (see above for that)\n",
    "\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "\n",
    "index = VectorStoreIndex(nodes=nodes, llm=llm)\n",
    "\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "for query in queries:\n",
    "    response = query_engine.query(query)\n",
    "    print(f\"Answer to '{query}':\")\n",
    "    print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
